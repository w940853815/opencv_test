{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8章　物体跟踪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现基本背景差分器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "OPENCV_MAJOR_VERSION = int(cv2.__version__.split('.')[0])\n",
    "\n",
    "BLUR_RADIUS = 21\n",
    "# 腐蚀\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "# 膨胀\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "for i in range(10):\n",
    "    success, frame = cap.read()\n",
    "if not success:\n",
    "    exit(1)\n",
    "\n",
    "gray_background = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "gray_background = cv2.GaussianBlur(gray_background, (BLUR_RADIUS, BLUR_RADIUS), 0)\n",
    "success, frame = cap.read()\n",
    "while success:\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (BLUR_RADIUS, BLUR_RADIUS), 0)\n",
    "    diff = cv2.absdiff(gray_background, gray_frame)\n",
    "    _, thresh = cv2.threshold(diff, 40, 255, cv2.THRESH_BINARY)\n",
    "    cv2.erode(thresh, erode_kernel, thresh, iterations=2)\n",
    "    cv2.dilate(thresh, dilate_kernel, thresh, iterations=2)\n",
    "    if OPENCV_MAJOR_VERSION >= 4:\n",
    "        # OpenCV 4 or a later version is being used.\n",
    "        contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL,\n",
    "                                          cv2.CHAIN_APPROX_SIMPLE)\n",
    "    else:\n",
    "        # OpenCV 3 or an earlier version is being used.\n",
    "        # cv2.findContours has an extra return value.\n",
    "        # The extra return value is the thresholded image, which is\n",
    "        # unchanged, so we can ignore it.\n",
    "        _, contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL,\n",
    "                                             cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) > 4000:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "    cv2.imshow('diff', diff)\n",
    "    cv2.imshow('thresh', thresh)\n",
    "    cv2.imshow('detect', frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "    success, frame = cap.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用MOG背景差分器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(detectShadows=True)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n",
    "cap  = cv2.VideoCapture(\"data/hallway.mpg\")\n",
    "success, frame = cap.read()\n",
    "while success:\n",
    "    time.sleep(1)\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    _, thresh = cv2.threshold(fg_mask, 244, 255, cv2.THRESH_BINARY)\n",
    "    cv2.erode(thresh, erode_kernel, thresh, iterations=2)\n",
    "    cv2.dilate(thresh, dilate_kernel, thresh, iterations=2)\n",
    "    contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) > 1000:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "    cv2.imshow('mog', fg_mask)\n",
    "    cv2.imshow('thresh', thresh)\n",
    "    cv2.imshow('detection', frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "    success, frame = cap.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用KNN背景差分器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "bg_subtractor = cv2.createBackgroundSubtractorKNN(detectShadows=True)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 5))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (17, 11))\n",
    "cap  = cv2.VideoCapture(\"data/traffic.flv\")\n",
    "success, frame = cap.read()\n",
    "while success:\n",
    "    time.sleep(1)\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    _, thresh = cv2.threshold(fg_mask, 244, 255, cv2.THRESH_BINARY)\n",
    "    cv2.erode(thresh, erode_kernel, thresh, iterations=2)\n",
    "    cv2.dilate(thresh, dilate_kernel, thresh, iterations=2)\n",
    "    contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) > 1000:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "    cv2.imshow('knn', fg_mask)\n",
    "    cv2.imshow('thresh', thresh)\n",
    "    cv2.imshow('detection', frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "    success, frame = cap.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用GMG和其他背景差分器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "bg_subtractor = cv2.bgsegm.createBackgroundSubtractorGMG()\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (13, 9))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (17, 11))\n",
    "cap  = cv2.VideoCapture(\"data/traffic.flv\")\n",
    "success, frame = cap.read()\n",
    "while success:\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    cv2.imshow('gmg', fg_mask)\n",
    "    _, thresh = cv2.threshold(fg_mask, 244, 255, cv2.THRESH_BINARY)\n",
    "    cv2.erode(thresh, erode_kernel, thresh, iterations=2)\n",
    "    cv2.dilate(thresh, dilate_kernel, thresh, iterations=2)\n",
    "    contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) > 1000:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "    cv2.imshow('gmg', fg_mask)\n",
    "    cv2.imshow('thresh', thresh)\n",
    "    cv2.imshow('detection', frame)\n",
    "    k = cv2.waitKey(30)\n",
    "    if k == 27:\n",
    "        break\n",
    "    success, frame = cap.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现MeanShift示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(1)\n",
    "for i in range(10):\n",
    "    success, frame = cap.read()\n",
    "if not success:\n",
    "    exit(1)\n",
    "\n",
    "frame_h, frame_w =  frame.shape[:2]\n",
    "w = frame_w // 8\n",
    "h = frame_h // 8\n",
    "x = frame_w // 2 - w // 2\n",
    "y = frame_h // 2 - h // 2\n",
    "track_window = (x, y, w, h)\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "mask = None\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "term_crit = (cv2.TERM_CRITERIA_COUNT | cv2.TERM_CRITERIA_EPS, 10, 1)\n",
    "success, frame = cap.read()\n",
    "while success:\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    back_proj = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "    num_iters, track_window = cv2.meanShift(back_proj, track_window, term_crit)\n",
    "    x, y, w, h = track_window\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    cv2.imshow(\"back-projection\", back_proj)\n",
    "    cv2.imshow(\"meanshift\", frame)\n",
    "    k = cv2.waitKey(30)\n",
    "    if k == 27:\n",
    "        break\n",
    "    success, frame = cap.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用CamShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(1)\n",
    "for i in range(10):\n",
    "    success, frame = cap.read()\n",
    "if not success:\n",
    "    exit(1)\n",
    "\n",
    "frame_h, frame_w =  frame.shape[:2]\n",
    "w = frame_w // 8\n",
    "h = frame_h // 8\n",
    "x = frame_w // 2 - w // 2\n",
    "y = frame_h // 2 - h // 2\n",
    "track_window = (x, y, w, h)\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "mask = None\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "term_crit = (cv2.TERM_CRITERIA_COUNT | cv2.TERM_CRITERIA_EPS, 10, 1)\n",
    "success, frame = cap.read()\n",
    "while success:\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    back_proj = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "    rotated_rect, track_window = cv2.CamShift(back_proj, track_window, term_crit)\n",
    "    box_points = cv2.boxPoints(rotated_rect)\n",
    "    box_points = np.int0(box_points)\n",
    "    cv2.polylines(frame, [box_points], True, (255, 0, 0), 2)\n",
    "    cv2.imshow(\"back-projection\", back_proj)\n",
    "    cv2.imshow(\"camshift\", frame)\n",
    "    k = cv2.waitKey(30)\n",
    "    if k == 27:\n",
    "        break\n",
    "    success, frame = cap.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 跟踪鼠标光标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = np.zeros((800, 800, 3), np.uint8)\n",
    "kalman = cv2.KalmanFilter(4, 2)\n",
    "kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "kalman.processNoiseCov = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32) * 0.03\n",
    "last_measurement = None\n",
    "last_prediction = None\n",
    "\n",
    "def on_mouse_moved(event, x, y, flags, param):\n",
    "    global img, kalman, last_measurement, last_prediction\n",
    "    measurement = np.array([[x], [y]], np.float32)\n",
    "    if last_measurement is None:\n",
    "        kalman.statePre = np.array([[x],[y],[0],[0]], np.float32)\n",
    "        kalman.statePost = np.array([[x],[y],[0],[0]], np.float32)\n",
    "        prediction = measurement\n",
    "    else:\n",
    "        kalman.correct(measurement)\n",
    "        prediction = kalman.predict()\n",
    "        cv2.line(img, (int(last_measurement[0]), int(last_measurement[1])), (int(measurement[0]), int(measurement[1])), (0, 255, 0))\n",
    "        cv2.line(img, (int(last_prediction[0]), int(last_prediction[1])), (int(prediction[0]), int(prediction[1])), (0, 0, 255))\n",
    "    last_prediction = prediction.copy()\n",
    "    last_measurement = measurement\n",
    "cv2.namedWindow(\"kalman_tracker\")\n",
    "cv2.setMouseCallback(\"kalman_tracker\", on_mouse_moved)\n",
    "while True:\n",
    "    cv2.imshow(\"kalman_tracker\", img)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        cv2.imwrite(\"images/kalman.png\", img)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现行人类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class Pedestrain():\n",
    "    \n",
    "    def __init__(self, id ,hsv_frame, track_window):\n",
    "        self.id = id\n",
    "        self.track_window = track_window\n",
    "        self.term_crit = (cv2.TERM_CRITERIA_COUNT | cv2.TermCriteria_EPS, 10, 1)\n",
    "        x, y, w, h  = track_window\n",
    "        roi = hsv_frame[y:y+h, x:x+w]\n",
    "        roi_hist = cv2.calcHist([roi], [0], None, [16], [0, 180])\n",
    "        self.roi_hist = cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "        self.kalman = cv2.KalmanFilter(4, 2)\n",
    "        self.kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "        self.kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "        self.kalman.processNoiseCov = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32) * 0.03\n",
    "        cx = x+w/2\n",
    "        cy = y+h/2\n",
    "        self.kalman.statePre = np.array([[cx],[cy],[0],[0]], np.float32)\n",
    "        self.kalman.statePost = np.array([[cx],[cy],[0],[0]], np.float32)\n",
    "    \n",
    "    def update(self, frame, hsv_frame):\n",
    "        back_proj = cv2.calcBackProject([hsv_frame], [0], self.roi_hist, [0, 180], 1)\n",
    "        ret, self.track_window = cv2.meanShift(back_proj, self.track_window, self.term_crit)\n",
    "        x, y, w, h = self.track_window\n",
    "        center = np.array([x+w/2, y+h/2], np.float32)\n",
    "        prediction = self.kalman.predict()\n",
    "        estimate = self.kalman.correct(center)\n",
    "        center_offset = estimate[:,0][:2] - center\n",
    "        self.track_window = (x + int(center_offset[0]), y + int(center_offset[1]), w, h)\n",
    "        x, y , w, h = self.track_window\n",
    "        cv2.circle(frame, (int(prediction[0]), int(prediction[1])), 4, (255, 0, 0), -1)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"ID: {self.id}\", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    \n",
    "def main():\n",
    "    cap = cv2.VideoCapture(\"data/pedestrians.avi\")\n",
    "    bg_subtractor = cv2.createBackgroundSubtractorKNN()\n",
    "    history_length = 20\n",
    "    bg_subtractor.setHistory(history_length)\n",
    "\n",
    "    erode_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    dilate_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (8, 3))\n",
    "    pedestrians = []\n",
    "    num_history_frames_populated = 0\n",
    "    while True:\n",
    "        grabbed, frame = cap.read()\n",
    "        if (grabbed is False):\n",
    "            break\n",
    "        fg_mask = bg_subtractor.apply(frame)\n",
    "        if num_history_frames_populated < history_length:\n",
    "            num_history_frames_populated += 1\n",
    "            continue\n",
    "        _, thresh = cv2.threshold(fg_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "        cv2.erode(thresh, erode_kernel, thresh, iterations=2)\n",
    "        cv2.dilate(thresh, dilate_kernel, thresh, iterations=2)\n",
    "        contours, heir = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        should_initialize_pedestrians = len(pedestrians) == 0\n",
    "        id = 0\n",
    "        for c in contours:\n",
    "            if cv2.contourArea(c) > 500:\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 1)\n",
    "                if should_initialize_pedestrians:\n",
    "                    pedestrians.append(Pedestrain(id, hsv_frame, (x, y, w, h)))\n",
    "        for pedestrain in pedestrians:\n",
    "            pedestrain.update(frame, hsv_frame)\n",
    "        cv2.imshow(\"Pedestrains Tracked\", frame)\n",
    "        k = cv2.waitKey(110)\n",
    "        if k == 27:\n",
    "            break\n",
    "main()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
