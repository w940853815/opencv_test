{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第9章　摄像头模型和增强现实"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import timeit\n",
    "import cv2\n",
    "import numpy as np\n",
    "gray_img = cv2.cvtColor(bg_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def convert_to_gray(src, dst=None):\n",
    "    weight = 1.0 / 3.0\n",
    "    m = np.array([weight, weight, weight], np.float32)\n",
    "    return cv2.transform(src, m, dst)\n",
    "\n",
    "def map_point_onto_plane(point_2D, image_size, image_scale):\n",
    "    x, y = point_2D\n",
    "    w, h = image_size\n",
    "    return (image_scale * (x-0.5*w), image_scale * (y-0.5*h), 0.0)\n",
    "\n",
    "def map_points_to_plane(points_2D, image_size, image_real_height):\n",
    "    w, h = image_size\n",
    "    image_scale = image_real_height / h\n",
    "    points_3D = [map_point_onto_plane(point_2D, image_size, image_scale) for point_2D in points_2D]\n",
    "    return np.array(points_3D, np.float32)\n",
    "\n",
    "def map_vertices_to_plane(image_size, image_real_height):\n",
    "    w, h = image_size\n",
    "    vertices_2D = [(0, 0), (w, 0), (w, h), (0, h)]\n",
    "    vertex_indices_by_face = [[0, 1, 2, 3]]\n",
    "    vertices_3D = map_points_to_plane(vertices_2D, image_size, image_real_height)\n",
    "    return vertices_3D, vertex_indices_by_face\n",
    "\n",
    "class ImageTrackingDemo():\n",
    "\n",
    "    def __init__(self, capture, diagonal_fov_degrees=70.0, target_fps=25.0,\n",
    "                reference_image_path=\"images/reference_image.png\",\n",
    "                reference_image_real_height=1.0):\n",
    "        self._capture = capture\n",
    "        success, trail_image = capture.read()\n",
    "        if success:\n",
    "            h , w = trail_image.shape[:2]\n",
    "        else:\n",
    "            w = capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "            h = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        self._image_size = (w, h)\n",
    "        diagonal_image_size = (w ** 2.0 + h ** 2.0) ** 0.5\n",
    "        diagonal_fov_radians = diagonal_fov_degrees * math.pi / 180.0\n",
    "        focal_length = 0.5 * diagonal_image_size / math.tan(0.5 * diagonal_fov_radians)\n",
    "        self._camera_matrix = np.array([[focal_length, 0.0, 0.5 * w], [0.0, focal_length, 0.5 * h], [0.0, 0.0, 1.0]], np.float32)\n",
    "        self._distortion_coefficients = None\n",
    "        self._kalman = cv2.KalmanFilter(18, 6)\n",
    "        self._kalman.processNoiseCov = np.identity(18, np.float32) * 1e-5\n",
    "        self._kalman.measurementNoiseCov = np.identity(6, np.float32) * 1e-2\n",
    "        self._kalman.errorCovPost = np.identity(18, np.float32)\n",
    "        self._kalman.measuremnetMartrix = np.array(\n",
    "            [\n",
    "                [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "            ], np.float32\n",
    "        )\n",
    "        self._init_kalman_transition_martrix(target_fps)\n",
    "        self._was_tracking = False\n",
    "        self._reference_image_real_height = reference_image_real_height\n",
    "        reference_axis_length = 0.5 * reference_image_real_height\n",
    "        self._bgr_image = None\n",
    "        self._gray_image = None\n",
    "        self._mask = None\n",
    "        patchSize = 31\n",
    "        self._feature_detector = cv2.ORB_create(nfeatures=250, scaleFactor=1.2, nlevels=16, edgeThreshold=patchSize, patchSize=patchSize)\n",
    "        bgr_reference_image = cv2.imread(reference_image_path, cv2.IMREAD_COLOR)\n",
    "        reference_image_h, reference_image_w = bgr_reference_image.shape[:2]\n",
    "        reference_image_resize_factor = (2.0 * h) / reference_image_h\n",
    "        bgr_reference_image = cv2.resize(bgr_reference_image, (0, 0), None, reference_image_resize_factor, reference_image_resize_factor, cv2.INTER_CUBIC)\n",
    "        gray_reference_image = convert_to_gray(bgr_reference_image)\n",
    "        reference_mask = np.empty_like(gray_reference_image)\n",
    "        reference_keypoints = []\n",
    "        self._reference_descriptors = np.empty((0, 32), np.uint8)\n",
    "        num_segments_y = 6\n",
    "        num_segments_x = 6\n",
    "        for segment_y, segment_x in np.ndindex((num_segments_y, num_segments_x)):\n",
    "            y0 = reference_image_h * segment_y // num_segments_y - patchSize\n",
    "            x0 = reference_image_w * segment_x // num_segments_x - patchSize\n",
    "            y1 = reference_image_h * (segment_y + 1) //num_segments_y + patchSize\n",
    "            x1 = reference_image_w * (segment_x + 1) //num_segments_x + patchSize\n",
    "            reference_mask.fill(0)\n",
    "            cv2.rectangle(reference_mask, (x0, y0), (x1, y1), 255, cv2.FILLED)\n",
    "            more_reference_keypoints, more_reference_descriptors = self._feature_detector.detectAndCompute(gray_reference_image, reference_mask)\n",
    "            if more_reference_descriptors is None:\n",
    "                continue\n",
    "            reference_keypoints += more_reference_keypoints\n",
    "            self._reference_descriptors = np.vstack((self._reference_descriptors, more_reference_descriptors))\n",
    "            cv2.drawKeypoints(gray_reference_image, reference_keypoints, bgr_reference_image, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        ext_i = reference_image_path.rfind('.')\n",
    "        reference_image_keypoints_path = reference_image_path[:ext_i] + \"_keypoints\" + reference_image_path[ext_i:]\n",
    "        cv2.imwrite(reference_image_keypoints_path, bgr_reference_image)\n",
    "        FlANN_INDEX_LSH = 6\n",
    "        index_params = dict(algorithm=FlANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "        search_params = dict()\n",
    "        self._descriptor_matcher = cv2.FlannBasedMatcher(index_params, search_params)       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
