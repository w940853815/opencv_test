{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第9章　摄像头模型和增强现实"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import timeit\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def convert_to_gray(src, dst=None):\n",
    "    weight = 1.0 / 3.0\n",
    "    m = np.array([[weight, weight, weight]], np.float32)\n",
    "    return cv2.transform(src, m, dst)\n",
    "\n",
    "def map_point_onto_plane(point_2D, image_size, image_scale):\n",
    "    x, y = point_2D\n",
    "    w, h = image_size\n",
    "    return (image_scale * (x - 0.5 * w), image_scale * (y - 0.5 * h), 0.0)\n",
    "\n",
    "def map_points_to_plane(points_2D, image_size, image_real_height):\n",
    "    w, h = image_size\n",
    "    image_scale = image_real_height / h\n",
    "    points_3D = [map_point_onto_plane(point_2D, image_size, image_scale) for point_2D in points_2D]\n",
    "    return np.array(points_3D, np.float32)\n",
    "\n",
    "def map_vertices_to_plane(image_size, image_real_height):\n",
    "    w, h = image_size\n",
    "    vertices_2D = [(0, 0), (w, 0), (w, h), (0, h)]\n",
    "    vertex_indices_by_face = [[0, 1, 2, 3]]\n",
    "    vertices_3D = map_points_to_plane(vertices_2D, image_size, image_real_height)\n",
    "    return vertices_3D, vertex_indices_by_face\n",
    "\n",
    "class ImageTrackingDemo():\n",
    "\n",
    "    def __init__(self, capture, diagonal_fov_degrees=70.0, target_fps=25.0,\n",
    "                reference_image_path=\"images/reference_image.png\",\n",
    "                reference_image_real_height=1.0):\n",
    "        self._capture = capture\n",
    "        success, trail_image = capture.read()\n",
    "        if success:\n",
    "            h , w = trail_image.shape[:2]\n",
    "        else:\n",
    "            w = capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "            h = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        self._image_size = (w, h)\n",
    "        diagonal_image_size = (w ** 2.0 + h ** 2.0) ** 0.5\n",
    "        diagonal_fov_radians = diagonal_fov_degrees * math.pi / 180.0\n",
    "        focal_length = 0.5 * diagonal_image_size / math.tan(0.5 * diagonal_fov_radians)\n",
    "        self._camera_matrix = np.array([[focal_length, 0.0, 0.5 * w], \n",
    "                                        [0.0, focal_length, 0.5 * h], \n",
    "                                        [0.0, 0.0, 1.0]], np.float32)\n",
    "        self._distortion_coefficients = None\n",
    "        self._rotation_vector = None\n",
    "        self._translation_vector = None\n",
    "        self._kalman = cv2.KalmanFilter(18, 6)\n",
    "        self._kalman.processNoiseCov = np.identity(18, np.float32) * 1e-5\n",
    "        self._kalman.measurementNoiseCov = np.identity(6, np.float32) * 1e-2\n",
    "        self._kalman.errorCovPost = np.identity(18, np.float32)\n",
    "        self._kalman.measurementMatrix = np.array(\n",
    "            [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],\n",
    "            np.float32)\n",
    "        self._init_kalman_transition_matrix(target_fps)\n",
    "        self._was_tracking = False\n",
    "        self._reference_image_real_height = reference_image_real_height\n",
    "        reference_axis_length = 0.5 * reference_image_real_height\n",
    "        self._reference_axis_points_3D = np.array(\n",
    "            [[0.0, 0.0, 0.0],\n",
    "             [-reference_axis_length, 0.0, 0.0],\n",
    "             [0.0, -reference_axis_length, 0.0],\n",
    "             [0.0, 0.0, -reference_axis_length]], np.float32)\n",
    "        self._bgr_image = None\n",
    "        self._gray_image = None\n",
    "        self._mask = None\n",
    "        patchSize = 31\n",
    "        self._feature_detector = cv2.ORB_create(nfeatures=250, scaleFactor=1.2, nlevels=16, edgeThreshold=patchSize, patchSize=patchSize)\n",
    "        bgr_reference_image = cv2.imread(reference_image_path, cv2.IMREAD_COLOR)\n",
    "        reference_image_h, reference_image_w = bgr_reference_image.shape[:2]\n",
    "        reference_image_resize_factor = (2.0 * h) / reference_image_h\n",
    "        bgr_reference_image = cv2.resize(bgr_reference_image, (0, 0), None, reference_image_resize_factor, reference_image_resize_factor, cv2.INTER_CUBIC)\n",
    "        gray_reference_image = convert_to_gray(bgr_reference_image)\n",
    "        reference_mask = np.empty_like(gray_reference_image)\n",
    "        reference_keypoints = []\n",
    "        self._reference_descriptors = np.empty((0, 32), np.uint8)\n",
    "        num_segments_y = 6\n",
    "        num_segments_x = 6\n",
    "        for segment_y, segment_x in np.ndindex((num_segments_y, num_segments_x)):\n",
    "            y0 = reference_image_h * segment_y // num_segments_y - patchSize\n",
    "            x0 = reference_image_w * segment_x // num_segments_x - patchSize\n",
    "            y1 = reference_image_h * (segment_y + 1) //num_segments_y + patchSize\n",
    "            x1 = reference_image_w * (segment_x + 1) //num_segments_x + patchSize\n",
    "            reference_mask.fill(0)\n",
    "            cv2.rectangle(reference_mask, (x0, y0), (x1, y1), 255, cv2.FILLED)\n",
    "            more_reference_keypoints, more_reference_descriptors = self._feature_detector.detectAndCompute(gray_reference_image, reference_mask)\n",
    "            if more_reference_descriptors is None:\n",
    "                continue\n",
    "            reference_keypoints += more_reference_keypoints\n",
    "            self._reference_descriptors = np.vstack((self._reference_descriptors, more_reference_descriptors))\n",
    "        cv2.drawKeypoints(gray_reference_image, reference_keypoints, bgr_reference_image, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        ext_i = reference_image_path.rfind('.')\n",
    "        reference_image_keypoints_path = reference_image_path[:ext_i] + \"_keypoints\" + reference_image_path[ext_i:]\n",
    "        cv2.imwrite(reference_image_keypoints_path, bgr_reference_image)\n",
    "        FlANN_INDEX_LSH = 6\n",
    "        index_params = dict(algorithm=FlANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "        search_params = dict()\n",
    "        self._descriptor_matcher = cv2.FlannBasedMatcher(index_params, search_params)    \n",
    "        self._descriptor_matcher.add([self._reference_descriptors])\n",
    "        reference_points_2D = [keypoint.pt for keypoint in reference_keypoints]\n",
    "        self._reference_points_3D = map_points_to_plane(reference_points_2D, \n",
    "                                    gray_reference_image.shape[::-1], reference_image_real_height)\n",
    "        (self._reference_vertices_3D, self._reference_vertex_idices_by_face) = map_vertices_to_plane(\n",
    "            gray_reference_image.shape[::-1], reference_image_real_height\n",
    "        )\n",
    "    \n",
    "    def run(self):\n",
    "        num_images_captured = 0\n",
    "        start_time = timeit.default_timer()\n",
    "        while cv2.waitKey(1) != 27:\n",
    "            success, self._bgr_image = self._capture.read(self._bgr_image)\n",
    "            if success:\n",
    "                num_images_captured += 1\n",
    "                self._track_object()\n",
    "                cv2.imshow(\"Image Trackubg\", self._bgr_image)\n",
    "            delta_time = timeit.default_timer() - start_time\n",
    "            if delta_time > 0.0:\n",
    "                fps = num_images_captured / delta_time\n",
    "                self._init_kalman_transition_matrix(fps)\n",
    "\n",
    "    def _track_object(self):\n",
    "        self._gray_image = convert_to_gray(self._bgr_image, self._gray_image)\n",
    "        if self._mask is None:\n",
    "            self._mask = np.full_like(self._gray_image, 255)\n",
    "        keypoints, descriptors = self._feature_detector.detectAndCompute(self._gray_image, self._mask)\n",
    "        matches = self._descriptor_matcher.knnMatch(descriptors, 2)\n",
    "        good_matches = [match[0] for match in matches if len(match) > 1 and match[0].distance <0.6 * match[1].distance]\n",
    "        good_keypoints = [keypoints[match.queryIdx] for match in good_matches]\n",
    "        cv2.drawKeypoints(self._gray_image, good_keypoints, self._bgr_image, (0, 0, 255))\n",
    "        min_good_matches_to_start_tracking = 8\n",
    "        min_good_matches_to_continue_tracking = 6\n",
    "        num_good_matches = len(good_matches)\n",
    "        if num_good_matches < min_good_matches_to_start_tracking:\n",
    "            self._was_tracking = False\n",
    "            self._mask.fill(255)\n",
    "        elif num_good_matches >= min_good_matches_to_continue_tracking or self._was_tracking:\n",
    "            good_points_2D = np.array([[keypoint.pt] for keypoint in good_keypoints], np.float32)\n",
    "            good_points_3D = np.array([[self._reference_points_3D[match.trainIdx]] for match in good_matches], np.float32)\n",
    "            (success, self._rotation_vector, self._translation_vector, inlier_indices) = cv2.solvePnPRansac(\n",
    "                good_points_3D, good_points_2D, self._camera_matrix, self._distortion_coefficients, self._rotation_vector, self._translation_vector, useExtrinsicGuess=False, iterationsCount=100, reprojectionError=8.0, confidence=0.99, flags=cv2.SOLVEPNP_ITERATIVE\n",
    "            )\n",
    "            if success:\n",
    "                if not self._was_tracking:\n",
    "                    self._init_kalman_state_matrices()\n",
    "                self._was_tracking = True\n",
    "                self._apply_kalman()\n",
    "                inlier_keypoints = [good_keypoints[i] for i in inlier_indices.flat]\n",
    "                cv2.drawKeypoints(self._bgr_image, inlier_keypoints, self._bgr_image, (0, 255, 0))\n",
    "                self._draw_onject_axes()\n",
    "                self._make_and_draw_object_mask()\n",
    "\n",
    "    def _init_kalman_transition_matrix(self, fps):\n",
    "        if fps <= 0:\n",
    "            return\n",
    "        vel = 1.0 / fps\n",
    "        acc = 0.5 * (vel ** 2.0)\n",
    "        self._kalman.transitionMatrix = np.array(\n",
    "            [[1.0, 0.0, 0.0, vel, 0.0, 0.0, acc, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 1.0, 0.0, 0.0, vel, 0.0, 0.0, acc, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 1.0, 0.0, 0.0, vel, 0.0, 0.0, acc,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, vel, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, vel, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, vel,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              1.0, 0.0, 0.0, vel, 0.0, 0.0, acc, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 1.0, 0.0, 0.0, vel, 0.0, 0.0, acc, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 1.0, 0.0, 0.0, vel, 0.0, 0.0, acc],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, vel, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, vel, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, vel],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]],\n",
    "            np.float32)\n",
    "\n",
    "    def _init_kalman_state_matrices(self):\n",
    "        t_x, t_y, t_z = self._translation_vector.flat\n",
    "        r_x, r_y, r_z = self._rotation_vector.flat\n",
    "        self._kalman.statePre = np.array(\n",
    "            [[t_x], [t_y], [t_z],\n",
    "             [0.0], [0.0], [0.0],\n",
    "             [0.0], [0.0], [0.0],\n",
    "             [r_x], [r_y], [r_z],\n",
    "             [0.0], [0.0], [0.0],\n",
    "             [0.0], [0.0], [0.0]], np.float32)\n",
    "        self._kalman.statePost = np.array(\n",
    "            [[t_x], [t_y], [t_z],\n",
    "             [0.0], [0.0], [0.0],\n",
    "             [0.0], [0.0], [0.0],\n",
    "             [r_x], [r_y], [r_z],\n",
    "             [0.0], [0.0], [0.0],\n",
    "             [0.0], [0.0], [0.0]], np.float32)\n",
    "\n",
    "    def _draw_onject_axes(self):\n",
    "        points_2D, jacobian = cv2.projectPoints(self._reference_axis_points_3D, self._rotation_vector, self._translation_vector, self._camera_matrix, self._distortion_coefficients)\n",
    "        origin = (int(points_2D[0, 0, 0]), int(points_2D[0, 0, 1]))\n",
    "        right = (int(points_2D[1, 0, 0]), int(points_2D[1, 0, 1]))\n",
    "        up = (int(points_2D[2, 0, 0]), int(points_2D[2, 0, 1]))\n",
    "        forward = (int(points_2D[3, 0, 0]), int(points_2D[3, 0, 1]))\n",
    "        cv2.arrowedLine(self._bgr_image, origin, right, (0, 0, 255))\n",
    "        cv2.arrowedLine(self._bgr_image, origin, up, (0, 255, 0))\n",
    "        cv2.arrowedLine(self._bgr_image, origin, forward, (255, 0, 0))\n",
    "\n",
    "    def _make_and_draw_object_mask(self):\n",
    "        vertices_2D, jacobian = cv2.projectPoints(self._reference_vertices_3D, self._rotation_vector, self._translation_vector, self._camera_matrix, self._distortion_coefficients)\n",
    "        vertices_2D = vertices_2D.astype(np.int32)\n",
    "        self._mask.fill(0)\n",
    "        for vertex_indices in self._reference_vertex_idices_by_face:\n",
    "            cv2.fillConvexPoly(self._mask, vertices_2D[vertex_indices], 255)\n",
    "        cv2.subtract(self._bgr_image, 48, self._bgr_image, self._mask)\n",
    "\n",
    "    def _apply_kalman(self):\n",
    "        self._kalman.predict()\n",
    "        t_x, t_y, t_z = self._translation_vector.flat\n",
    "        r_x, r_y, r_z = self._rotation_vector.flat\n",
    "        estimate = self._kalman.correct(np.array([\n",
    "            [t_x, t_y, t_z], \n",
    "            [r_x, r_y, r_z]\n",
    "        ], np.float32))\n",
    "        self._translation_vector = estimate[0:3]\n",
    "        self._rotation_vector = estimate[9:12]\n",
    "    \n",
    "def main():\n",
    "    capture = cv2.VideoCapture(1)\n",
    "    capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    diagonal_fov_degrees = 70.0\n",
    "    target_fps = 25.0\n",
    "    demo = ImageTrackingDemo(capture, diagonal_fov_degrees, target_fps)\n",
    "    demo.run()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import math\n",
    "import timeit\n",
    "\n",
    "import cv2\n",
    "import numpy\n",
    "\n",
    "def convert_to_gray(src, dst=None):\n",
    "    weight = 1.0 / 3.0\n",
    "    m = numpy.array([[weight, weight, weight]], numpy.float32)\n",
    "    return cv2.transform(src, m, dst)\n",
    "\n",
    "\n",
    "def map_point_onto_plane(point_2D, image_size, image_scale):\n",
    "    x, y = point_2D\n",
    "    w, h = image_size\n",
    "    return (image_scale * (x - 0.5 * w),\n",
    "            image_scale * (y - 0.5 * h),\n",
    "            0.0)\n",
    "\n",
    "\n",
    "def map_points_to_plane(points_2D, image_size, image_real_height):\n",
    "\n",
    "    w, h = image_size\n",
    "    image_scale = image_real_height / h\n",
    "\n",
    "    points_3D = [map_point_onto_plane(\n",
    "                     point_2D, image_size, image_scale)\n",
    "                 for point_2D in points_2D]\n",
    "    return numpy.array(points_3D, numpy.float32)\n",
    "\n",
    "\n",
    "def map_vertices_to_plane(image_size, image_real_height):\n",
    "\n",
    "    w, h = image_size\n",
    "\n",
    "    vertices_2D = [(0, 0), (w, 0), (w, h), (0, h)]\n",
    "    vertex_indices_by_face = [[0, 1, 2, 3]]\n",
    "\n",
    "    vertices_3D = map_points_to_plane(\n",
    "        vertices_2D, image_size, image_real_height)\n",
    "    return vertices_3D, vertex_indices_by_face\n",
    "\n",
    "\n",
    "class ImageTrackingDemo():\n",
    "\n",
    "\n",
    "    def __init__(self, capture, diagonal_fov_degrees=70.0,\n",
    "                 target_fps=25.0,\n",
    "                 reference_image_path='images/reference_image.png',\n",
    "                 reference_image_real_height=1.0):\n",
    "\n",
    "        self._capture = capture\n",
    "        success, trial_image = capture.read()\n",
    "        if success:\n",
    "            # Use the actual image dimensions.\n",
    "            h, w = trial_image.shape[:2]\n",
    "        else:\n",
    "            # Use the nominal image dimensions.\n",
    "            w = capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "            h = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        self._image_size = (w, h)\n",
    "\n",
    "        diagonal_image_size = (w ** 2.0 + h ** 2.0) ** 0.5\n",
    "        diagonal_fov_radians = \\\n",
    "            diagonal_fov_degrees * math.pi / 180.0\n",
    "        focal_length = 0.5 * diagonal_image_size / math.tan(\n",
    "            0.5 * diagonal_fov_radians)\n",
    "        self._camera_matrix = numpy.array(\n",
    "            [[focal_length, 0.0, 0.5 * w],\n",
    "             [0.0, focal_length, 0.5 * h],\n",
    "             [0.0, 0.0, 1.0]], numpy.float32)\n",
    "\n",
    "        self._distortion_coefficients = None\n",
    "\n",
    "        self._rotation_vector = None\n",
    "        self._translation_vector = None\n",
    "\n",
    "        self._kalman = cv2.KalmanFilter(18, 6)\n",
    "\n",
    "        self._kalman.processNoiseCov = numpy.identity(\n",
    "            18, numpy.float32) * 1e-5\n",
    "        self._kalman.measurementNoiseCov = numpy.identity(\n",
    "            6, numpy.float32) * 1e-2\n",
    "        self._kalman.errorCovPost = numpy.identity(\n",
    "            18, numpy.float32)\n",
    "\n",
    "        self._kalman.measurementMatrix = numpy.array(\n",
    "            [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],\n",
    "            numpy.float32)\n",
    "\n",
    "        self._init_kalman_transition_matrix(target_fps)\n",
    "\n",
    "        self._was_tracking = False\n",
    "\n",
    "        self._reference_image_real_height = \\\n",
    "            reference_image_real_height\n",
    "        reference_axis_length = 0.5 * reference_image_real_height\n",
    "\n",
    "        #-----------------------------------------------------------------------------\n",
    "        # BEWARE!\n",
    "        #-----------------------------------------------------------------------------\n",
    "        #\n",
    "        # OpenCV's coordinate system has non-standard axis directions:\n",
    "        #   +X:  object's left; viewer's right from frontal view\n",
    "        #   +Y:  down\n",
    "        #   +Z:  object's backward; viewer's forward from frontal view\n",
    "        #\n",
    "        # Negate them all to convert to right-handed coordinate system (like OpenGL):\n",
    "        #   +X:  object's right; viewer's left from frontal view\n",
    "        #   +Y:  up\n",
    "        #   +Z:  object's forward; viewer's backward from frontal view\n",
    "        #\n",
    "        #-----------------------------------------------------------------------------\n",
    "        self._reference_axis_points_3D = numpy.array(\n",
    "            [[0.0, 0.0, 0.0],\n",
    "             [-reference_axis_length, 0.0, 0.0],\n",
    "             [0.0, -reference_axis_length, 0.0],\n",
    "             [0.0, 0.0, -reference_axis_length]], numpy.float32)\n",
    "\n",
    "        self._bgr_image = None\n",
    "        self._gray_image = None\n",
    "        self._mask = None\n",
    "\n",
    "        # Create and configure the feature detector.\n",
    "        patchSize = 31\n",
    "        self._feature_detector = cv2.ORB_create(\n",
    "            nfeatures=250, scaleFactor=1.2, nlevels=16,\n",
    "            edgeThreshold=patchSize, patchSize=patchSize)\n",
    "\n",
    "        bgr_reference_image = cv2.imread(\n",
    "            reference_image_path, cv2.IMREAD_COLOR)\n",
    "        reference_image_h, reference_image_w = \\\n",
    "            bgr_reference_image.shape[:2]\n",
    "        reference_image_resize_factor = \\\n",
    "            (2.0 * h) / reference_image_h\n",
    "        bgr_reference_image = cv2.resize(\n",
    "            bgr_reference_image, (0, 0), None,\n",
    "            reference_image_resize_factor,\n",
    "            reference_image_resize_factor, cv2.INTER_CUBIC)\n",
    "        gray_reference_image = convert_to_gray(bgr_reference_image)\n",
    "        reference_mask = numpy.empty_like(gray_reference_image)\n",
    "\n",
    "        # Find keypoints and descriptors for multiple segments of\n",
    "        # the reference image.\n",
    "        reference_keypoints = []\n",
    "        self._reference_descriptors = numpy.empty(\n",
    "            (0, 32), numpy.uint8)\n",
    "        num_segments_y = 6\n",
    "        num_segments_x = 6\n",
    "        for segment_y, segment_x in numpy.ndindex(\n",
    "                (num_segments_y, num_segments_x)):\n",
    "            y0 = reference_image_h * \\\n",
    "                segment_y // num_segments_y - patchSize\n",
    "            x0 = reference_image_w * \\\n",
    "                segment_x // num_segments_x - patchSize\n",
    "            y1 = reference_image_h * \\\n",
    "                (segment_y + 1) // num_segments_y + patchSize\n",
    "            x1 = reference_image_w * \\\n",
    "                (segment_x + 1) // num_segments_x + patchSize\n",
    "            reference_mask.fill(0)\n",
    "            cv2.rectangle(\n",
    "                reference_mask, (x0, y0), (x1, y1), 255, cv2.FILLED)\n",
    "            more_reference_keypoints, more_reference_descriptors = \\\n",
    "                self._feature_detector.detectAndCompute(\n",
    "                    gray_reference_image, reference_mask)\n",
    "            if more_reference_descriptors is None:\n",
    "                # No keypoints were found for this segment.\n",
    "                continue\n",
    "            reference_keypoints += more_reference_keypoints\n",
    "            self._reference_descriptors = numpy.vstack(\n",
    "                (self._reference_descriptors,\n",
    "                 more_reference_descriptors))\n",
    "\n",
    "        cv2.drawKeypoints(\n",
    "            gray_reference_image, reference_keypoints,\n",
    "            bgr_reference_image,\n",
    "            flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "        ext_i = reference_image_path.rfind('.')\n",
    "        reference_image_keypoints_path = \\\n",
    "            reference_image_path[:ext_i] + '_keypoints' + \\\n",
    "            reference_image_path[ext_i:]\n",
    "        cv2.imwrite(\n",
    "            reference_image_keypoints_path, bgr_reference_image)\n",
    "\n",
    "        FLANN_INDEX_LSH = 6\n",
    "        index_params = dict(algorithm=FLANN_INDEX_LSH,\n",
    "                            table_number=6, key_size=12,\n",
    "                            multi_probe_level=1)\n",
    "        search_params = dict()\n",
    "        self._descriptor_matcher = cv2.FlannBasedMatcher(\n",
    "            index_params, search_params)\n",
    "        self._descriptor_matcher.add([self._reference_descriptors])\n",
    "\n",
    "        reference_points_2D = [keypoint.pt\n",
    "                               for keypoint in reference_keypoints]\n",
    "        self._reference_points_3D = map_points_to_plane(\n",
    "            reference_points_2D, gray_reference_image.shape[::-1],\n",
    "            reference_image_real_height)\n",
    "\n",
    "        (self._reference_vertices_3D,\n",
    "         self._reference_vertex_indices_by_face) = \\\n",
    "            map_vertices_to_plane(\n",
    "                    gray_reference_image.shape[::-1],\n",
    "                    reference_image_real_height)\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        num_images_captured = 0\n",
    "        start_time = timeit.default_timer()\n",
    "\n",
    "        while cv2.waitKey(1) != 27:  # Escape\n",
    "            success, self._bgr_image = self._capture.read(\n",
    "                self._bgr_image)\n",
    "            if success:\n",
    "                num_images_captured += 1\n",
    "                self._track_object()\n",
    "                cv2.imshow('Image Tracking', self._bgr_image)\n",
    "            delta_time = timeit.default_timer() - start_time\n",
    "            if delta_time > 0.0:\n",
    "                fps = num_images_captured / delta_time\n",
    "                self._init_kalman_transition_matrix(fps)\n",
    "\n",
    "\n",
    "    def _track_object(self):\n",
    "\n",
    "        self._gray_image = convert_to_gray(\n",
    "            self._bgr_image, self._gray_image)\n",
    "\n",
    "        if self._mask is None:\n",
    "            self._mask = numpy.full_like(self._gray_image, 255)\n",
    "\n",
    "        keypoints, descriptors = \\\n",
    "            self._feature_detector.detectAndCompute(\n",
    "                self._gray_image, self._mask)\n",
    "\n",
    "        # Find the 2 best matches for each descriptor.\n",
    "        matches = self._descriptor_matcher.knnMatch(descriptors, 2)\n",
    "\n",
    "        # Filter the matches based on the distance ratio test.\n",
    "        good_matches = [\n",
    "            match[0] for match in matches\n",
    "            if len(match) > 1 and \\\n",
    "        \t\tmatch[0].distance < 0.6 * match[1].distance\n",
    "        ]\n",
    "\n",
    "        # Select the good keypoints and draw them in red.\n",
    "        good_keypoints = [keypoints[match.queryIdx]\n",
    "                          for match in good_matches]\n",
    "        cv2.drawKeypoints(self._gray_image, good_keypoints,\n",
    "                          self._bgr_image, (0, 0, 255))\n",
    "\n",
    "        min_good_matches_to_start_tracking = 8\n",
    "        min_good_matches_to_continue_tracking = 6\n",
    "        num_good_matches = len(good_matches)\n",
    "\n",
    "        if num_good_matches < min_good_matches_to_continue_tracking:\n",
    "            self._was_tracking = False\n",
    "            self._mask.fill(255)\n",
    "\n",
    "        elif num_good_matches >= \\\n",
    "                min_good_matches_to_start_tracking or \\\n",
    "                    self._was_tracking:\n",
    "            good_points_2D = numpy.array(\n",
    "                [[keypoint.pt] for keypoint in good_keypoints],\n",
    "                numpy.float32)\n",
    "\n",
    "            good_points_3D = numpy.array(\n",
    "                [[self._reference_points_3D[match.trainIdx]]\n",
    "                 for match in good_matches],\n",
    "                numpy.float32)\n",
    "\n",
    "            (success, self._rotation_vector,\n",
    "             self._translation_vector, inlier_indices) = \\\n",
    "                cv2.solvePnPRansac(good_points_3D, good_points_2D,\n",
    "                                   self._camera_matrix,\n",
    "                                   self._distortion_coefficients,\n",
    "                                   self._rotation_vector,\n",
    "                                   self._translation_vector,\n",
    "                                   useExtrinsicGuess=False,\n",
    "                                   iterationsCount=100,\n",
    "                                   reprojectionError=8.0,\n",
    "                                   confidence=0.99,\n",
    "                                   flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "            if success:\n",
    "\n",
    "                if not self._was_tracking:\n",
    "                    self._init_kalman_state_matrices()\n",
    "                self._was_tracking = True\n",
    "\n",
    "                self._apply_kalman()\n",
    "                inlier_keypoints = [good_keypoints[i]\n",
    "                                    for i in inlier_indices.flat]\n",
    "                cv2.drawKeypoints(self._bgr_image, inlier_keypoints,\n",
    "                                  self._bgr_image, (0, 255, 0))\n",
    "                self._draw_object_axes()\n",
    "                self._make_and_draw_object_mask()\n",
    "\n",
    "\n",
    "    def _init_kalman_transition_matrix(self, fps):\n",
    "\n",
    "        if fps <= 0.0:\n",
    "            return\n",
    "        vel = 1.0 / fps\n",
    "        acc = 0.5 * (vel ** 2.0)\n",
    "        self._kalman.transitionMatrix = numpy.array(\n",
    "            [[1.0, 0.0, 0.0, vel, 0.0, 0.0, acc, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 1.0, 0.0, 0.0, vel, 0.0, 0.0, acc, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 1.0, 0.0, 0.0, vel, 0.0, 0.0, acc,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, vel, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, vel, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, vel,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              1.0, 0.0, 0.0, vel, 0.0, 0.0, acc, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 1.0, 0.0, 0.0, vel, 0.0, 0.0, acc, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 1.0, 0.0, 0.0, vel, 0.0, 0.0, acc],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, vel, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, vel, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, vel],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
    "             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]],\n",
    "            numpy.float32)\n",
    "\n",
    "\n",
    "    def _init_kalman_state_matrices(self):\n",
    "\n",
    "        t_x, t_y, t_z = self._translation_vector.flat\n",
    "        r_x, r_y, r_z = self._rotation_vector.flat\n",
    "\n",
    "        self._kalman.statePre = numpy.array(\n",
    "            [[t_x], [t_y], [t_z],\n",
    "             [0.0], [0.0], [0.0],\n",
    "             [0.0], [0.0], [0.0],\n",
    "             [r_x], [r_y], [r_z],\n",
    "             [0.0], [0.0], [0.0],\n",
    "             [0.0], [0.0], [0.0]], numpy.float32)\n",
    "        self._kalman.statePost = numpy.array(\n",
    "            [[t_x], [t_y], [t_z],\n",
    "             [0.0], [0.0], [0.0],\n",
    "             [0.0], [0.0], [0.0],\n",
    "             [r_x], [r_y], [r_z],\n",
    "             [0.0], [0.0], [0.0],\n",
    "             [0.0], [0.0], [0.0]], numpy.float32)\n",
    "\n",
    "\n",
    "    def _apply_kalman(self):\n",
    "\n",
    "        self._kalman.predict()\n",
    "\n",
    "        t_x, t_y, t_z = self._translation_vector.flat\n",
    "        r_x, r_y, r_z = self._rotation_vector.flat\n",
    "\n",
    "        estimate = self._kalman.correct(numpy.array(\n",
    "            [[t_x], [t_y], [t_z],\n",
    "             [r_x], [r_y], [r_z]], numpy.float32))\n",
    "\n",
    "        self._translation_vector = estimate[0:3]\n",
    "        self._rotation_vector = estimate[9:12]\n",
    "\n",
    "\n",
    "    def _draw_object_axes(self):\n",
    "\n",
    "        points_2D, jacobian = cv2.projectPoints(\n",
    "            self._reference_axis_points_3D, self._rotation_vector,\n",
    "            self._translation_vector, self._camera_matrix,\n",
    "            self._distortion_coefficients)\n",
    "\n",
    "        origin = (int(points_2D[0, 0, 0]), int(points_2D[0, 0, 1]))\n",
    "        right = (int(points_2D[1, 0, 0]), int(points_2D[1, 0, 1]))\n",
    "        up = (int(points_2D[2, 0, 0]), int(points_2D[2, 0, 1]))\n",
    "        forward = (int(points_2D[3, 0, 0]), int(points_2D[3, 0, 1]))\n",
    "\n",
    "        # Draw the X axis in red.\n",
    "        cv2.arrowedLine(self._bgr_image, origin, right, (0, 0, 255))\n",
    "\n",
    "        # Draw the Y axis in green.\n",
    "        cv2.arrowedLine(self._bgr_image, origin, up, (0, 255, 0))\n",
    "\n",
    "        # Draw the Z axis in blue.\n",
    "        cv2.arrowedLine(\n",
    "            self._bgr_image, origin, forward, (255, 0, 0))\n",
    "\n",
    "\n",
    "    def _make_and_draw_object_mask(self):\n",
    "\n",
    "        # Project the object's vertices into the scene.\n",
    "        vertices_2D, jacobian = cv2.projectPoints(\n",
    "            self._reference_vertices_3D, self._rotation_vector,\n",
    "            self._translation_vector, self._camera_matrix,\n",
    "            self._distortion_coefficients)\n",
    "        vertices_2D = vertices_2D.astype(numpy.int32)\n",
    "\n",
    "        # Make a mask based on the projected vertices.\n",
    "        self._mask.fill(0)\n",
    "        for vertex_indices in \\\n",
    "                self._reference_vertex_indices_by_face:\n",
    "            cv2.fillConvexPoly(\n",
    "                self._mask, vertices_2D[vertex_indices], 255)\n",
    "\n",
    "        # Draw the mask in semi-transparent yellow.\n",
    "        cv2.subtract(\n",
    "            self._bgr_image, 48, self._bgr_image, self._mask)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    capture = cv2.VideoCapture(1)\n",
    "    capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    diagonal_fov_degrees = 70.0\n",
    "    target_fps = 25.0\n",
    "\n",
    "    demo = ImageTrackingDemo(\n",
    "        capture, diagonal_fov_degrees, target_fps)\n",
    "    demo.run()\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
